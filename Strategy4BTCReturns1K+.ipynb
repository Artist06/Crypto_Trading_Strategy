{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ta\n",
        "!pip install pandas_ta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yGtIVgDqZpC",
        "outputId": "5fe7c250-063b-4874-ebcd-d2e4bf50326b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ta\n",
            "  Downloading ta-0.11.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ta) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from ta) (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->ta) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ta) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->ta) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->ta) (1.17.0)\n",
            "Building wheels for collected packages: ta\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ta: filename=ta-0.11.0-py3-none-any.whl size=29412 sha256=e78fb669df6afa08d52f6ea1bb6a35d394f833bbd756715d15cdd5a8bcf5c8ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/67/4f/8a9f252836e053e532c6587a3230bc72a4deb16b03a829610b\n",
            "Successfully built ta\n",
            "Installing collected packages: ta\n",
            "Successfully installed ta-0.11.0\n",
            "Collecting pandas_ta\n",
            "  Downloading pandas_ta-0.3.14b.tar.gz (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.1/115.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from pandas_ta) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas->pandas_ta) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->pandas_ta) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pandas_ta) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->pandas_ta) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->pandas_ta) (1.17.0)\n",
            "Building wheels for collected packages: pandas_ta\n",
            "  Building wheel for pandas_ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandas_ta: filename=pandas_ta-0.3.14b0-py3-none-any.whl size=218909 sha256=8efcb4d1d2fd38324c09615c4834a673ab9d2370fa4c9efea873a375e89f2bc0\n",
            "  Stored in directory: /root/.cache/pip/wheels/69/00/ac/f7fa862c34b0e2ef320175100c233377b4c558944f12474cf0\n",
            "Successfully built pandas_ta\n",
            "Installing collected packages: pandas_ta\n",
            "Successfully installed pandas_ta-0.3.14b0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from ta.momentum import RSIIndicator\n",
        "from ta.trend import MACD, EMAIndicator, ADXIndicator\n",
        "from ta.volatility import AverageTrueRange\n",
        "from ta.trend import PSARIndicator\n",
        "from datetime import datetime\n",
        "\n",
        "# Load the historical data\n",
        "df = pd.read_csv('/content/BTC_2019_2023_1d.csv')  # Replace with your CSV file path\n",
        "\n",
        "df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')\n",
        "\n",
        "# Handle invalid dates (optional)\n",
        "df = df.dropna(subset=['datetime'])\n",
        "\n",
        "# Set 'datetime' as index\n",
        "df.set_index('datetime', inplace=True)\n",
        "\n",
        "# Ensure the required columns exist\n",
        "required_columns = ['open', 'high', 'low', 'close', 'signals']\n",
        "for column in required_columns:\n",
        "    if column not in df.columns:\n",
        "        if column == 'signals':\n",
        "            # Add a signals column initialized to 0\n",
        "            df[column] = 0\n",
        "        else:\n",
        "            # Add other missing columns initialized to NaN\n",
        "            df[column] = np.nan\n",
        "\n",
        "# Fill missing 'open', 'high', 'low', and 'close' columns if necessary\n",
        "df['open'].fillna(method='ffill', inplace=True)\n",
        "df['high'].fillna(df['close'], inplace=True)\n",
        "df['low'].fillna(df['close'], inplace=True)\n",
        "df['close'].fillna(method='ffill', inplace=True)\n",
        "\n",
        "# Calculate Heikin Ashi Candles\n",
        "df['HA_close'] = (df['open'] + df['high'] + df['low'] + df['close']) / 4\n",
        "df['HA_open'] = (df['open'].shift(1) + df['close'].shift(1)) / 2\n",
        "df['HA_high'] = df[['high', 'HA_open', 'HA_close']].max(axis=1)\n",
        "df['HA_low'] = df[['low', 'HA_open', 'HA_close']].min(axis=1)\n",
        "\n",
        "# Calculate technical indicators using the ta library\n",
        "df['RSI'] = RSIIndicator(close=df['HA_close'], window=14).rsi()\n",
        "macd = MACD(close=df['HA_close'], window_slow=26, window_fast=12, window_sign=9)\n",
        "df['MACD'] = macd.macd()\n",
        "df['MACD_Signal'] = macd.macd_signal()\n",
        "df['MACD_Hist'] = macd.macd_diff()\n",
        "df['ema_05'] = EMAIndicator(close=df['HA_close'], window=5).ema_indicator()\n",
        "df['ema_10'] = EMAIndicator(close=df['HA_close'], window=10).ema_indicator()\n",
        "df['ema_30'] = EMAIndicator(close=df['HA_close'], window=30).ema_indicator()\n",
        "df['ATR'] = AverageTrueRange(high=df['HA_high'], low=df['HA_low'], close=df['HA_close'], window=14).average_true_range()\n",
        "adx = ADXIndicator(high=df['HA_high'], low=df['HA_low'], close=df['HA_close'], window=14)\n",
        "df['ADX'] = adx.adx()\n",
        "df['ADX_Pos'] = adx.adx_pos()\n",
        "df['ADX_Neg'] = adx.adx_neg()\n",
        "psar = PSARIndicator(high=df['HA_high'], low=df['HA_low'], close=df['HA_close'], step=0.02, max_step=0.2)\n",
        "df['PSAR'] = psar.psar()\n",
        "\n",
        "# Initialize trading parameters\n",
        "rsi_buy_threshold = 30\n",
        "rsi_sell_threshold = 60\n",
        "adx_buy_threshold = 25\n",
        "adx_sell_threshold = 25\n",
        "trailing_stop_multiplier = 2\n",
        "transaction_cost = 0.00\n",
        "\n",
        "# Initialize variables\n",
        "in_position = False\n",
        "position_type = 0\n",
        "entry_price = 0\n",
        "highest_price = 0\n",
        "lowest_price = float('inf')\n",
        "net_profit = 0\n",
        "balance = 10000\n",
        "btc_amount = 0\n",
        "trade_count = 0\n",
        "winning_trades = 0\n",
        "losing_trades = 0\n",
        "max_drawdown_value = 0\n",
        "peak_balance = balance\n",
        "signal_history = [0] * len(df)\n",
        "trade_type = [None] * len(df)  # New column to track trade types\n",
        "balance_history = []\n",
        "\n",
        "# Loop through DataFrame row by row\n",
        "for i, (index, row) in enumerate(df.iterrows()):\n",
        "    current_price = row['close']\n",
        "    rsi = row['RSI']\n",
        "    macd = row['MACD']\n",
        "    macd_signal = row['MACD_Signal']\n",
        "    ema_10 = row['ema_10']\n",
        "    volume = row.get('volume', 0)\n",
        "    adx = row['ADX']\n",
        "    psar = row['PSAR']\n",
        "    atr = row['ATR']\n",
        "\n",
        "    # Volume threshold\n",
        "    volume_threshold = df['volume'].rolling(window=10).mean().iloc[i] if 'volume' in df.columns else 0\n",
        "\n",
        "    # Buy condition\n",
        "    buy_condition = (\n",
        "        (rsi > rsi_buy_threshold and ema_10 > row['ema_30'] and macd > macd_signal and current_price > ema_10) and\n",
        "        (adx > adx_buy_threshold and row['ADX_Pos'] > row['ADX_Neg']) and\n",
        "        (current_price > psar)\n",
        "    )\n",
        "\n",
        "    if buy_condition and not in_position:\n",
        "        entry_price = current_price\n",
        "        btc_amount = (balance * (1 - transaction_cost)) / entry_price\n",
        "        highest_price = entry_price\n",
        "        in_position = True\n",
        "        position_type = 1\n",
        "        trade_count += 1\n",
        "        signal_history[i] = 1  # Buy signal\n",
        "        trade_type[i] = 'long'  # Trade type\n",
        "\n",
        "    # Sell condition for long\n",
        "    sell_condition = (\n",
        "        (current_price <= psar) and\n",
        "        (rsi < rsi_sell_threshold and macd < macd_signal and adx < adx_sell_threshold)\n",
        "    )\n",
        "\n",
        "    if in_position and position_type == 1 and sell_condition:\n",
        "        balance = btc_amount * current_price * (1 - transaction_cost)\n",
        "        profit = (current_price - entry_price) * btc_amount\n",
        "        net_profit += profit\n",
        "        if profit > 0:\n",
        "            winning_trades += 1\n",
        "        else:\n",
        "            losing_trades += 1\n",
        "        in_position = False\n",
        "        signal_history[i] = -1  # Sell signal\n",
        "        trade_type[i] = 'exit'  # Trade type\n",
        "\n",
        "    balance_history.append(balance)\n",
        "    peak_balance = max(peak_balance, balance)\n",
        "    drawdown = (peak_balance - balance) / peak_balance\n",
        "    max_drawdown_value = max(max_drawdown_value, drawdown)\n",
        "\n",
        "# Add signal and trade_type columns to the DataFrame\n",
        "df['signals'] = signal_history\n",
        "df['trade_type'] = trade_type\n",
        "\n",
        "# Save the DataFrame to a CSV file with all original columns and the new columns\n",
        "current_time = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "output_filename = f'Strategy4BTCReturns1k+.csv'\n",
        "df.to_csv(output_filename, index=True)  # Include the index for datetime reference\n",
        "\n",
        "print(f\"File saved as {output_filename}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POwvUN-VqTOh",
        "outputId": "263e7bfb-a3a1-4713-df9f-519df80da4d4"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-c5e5edb79eb0>:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['open'].fillna(method='ffill', inplace=True)\n",
            "<ipython-input-29-c5e5edb79eb0>:33: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df['open'].fillna(method='ffill', inplace=True)\n",
            "<ipython-input-29-c5e5edb79eb0>:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['high'].fillna(df['close'], inplace=True)\n",
            "<ipython-input-29-c5e5edb79eb0>:35: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['low'].fillna(df['close'], inplace=True)\n",
            "<ipython-input-29-c5e5edb79eb0>:36: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['close'].fillna(method='ffill', inplace=True)\n",
            "<ipython-input-29-c5e5edb79eb0>:36: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df['close'].fillna(method='ffill', inplace=True)\n",
            "/usr/local/lib/python3.10/dist-packages/ta/trend.py:1030: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
            "  self._psar[i] = high2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved as Strategy4BTCReturns1k+.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_file_path = \"/content/Strategy4BTCReturns1k+.csv\""
      ],
      "metadata": {
        "id": "Pcf2V0IX62VF"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "w1jK2VHp38dW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "775814d3-1688-41d8-8239-573ef4748f40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'untrade-sdk' already exists and is not an empty directory.\n",
            "Processing ./untrade-sdk\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: untrade\n",
            "  Building wheel for untrade (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for untrade: filename=untrade-0.1.0-py3-none-any.whl size=5082 sha256=31197b3357f64b30ee36b40c8baf39aa49051fa7e417fb9f79f49806376b6a57\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/ce/9c/59addc63ec0e1b26a267abbcf20bcb13f36bc7f128da6e1cd6\n",
            "Successfully built untrade\n",
            "Installing collected packages: untrade\n",
            "  Attempting uninstall: untrade\n",
            "    Found existing installation: untrade 0.1.0\n",
            "    Uninstalling untrade-0.1.0:\n",
            "      Successfully uninstalled untrade-0.1.0\n",
            "Successfully installed untrade-0.1.0\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ztuntrade/untrade-sdk.git\n",
        "!pip install ./untrade-sdk/.\n",
        "\n",
        "import uuid\n",
        "import os\n",
        "from untrade.client import Client"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_backtest(csv_file_path):\n",
        "     client = Client()\n",
        "     result = client.backtest(\n",
        "         jupyter_id=\"test\",\n",
        "         file_path=csv_file_path,\n",
        "         leverage=1,\n",
        "     )\n",
        "     return result\n",
        "\n",
        "\n",
        "def perform_backtest_large_csv(csv_file_path):\n",
        "    client = Client()\n",
        "    file_id = str(uuid.uuid4())\n",
        "    chunk_size = 90 * 1024 * 1024  # 90 MB\n",
        "    total_size = os.path.getsize(csv_file_path)\n",
        "    total_chunks = (total_size + chunk_size - 1) // chunk_size\n",
        "    chunk_number = 0\n",
        "\n",
        "    # Handle small files\n",
        "    if total_size <= chunk_size:\n",
        "        total_chunks = 1\n",
        "        result = client.backtest(\n",
        "            file_path=csv_file_path,\n",
        "            leverage=1,\n",
        "            jupyter_id=\"test\",\n",
        "        )\n",
        "        for value in result:\n",
        "            print(value)\n",
        "        return result\n",
        "\n",
        "    # Process large files in chunks\n",
        "    with open(csv_file_path, \"rb\") as f:\n",
        "        while True:\n",
        "            chunk_data = f.read(chunk_size)\n",
        "            if not chunk_data:\n",
        "                break\n",
        "\n",
        "            # Save each chunk temporarily in /tmp\n",
        "            chunk_file_path = f\"/tmp/{file_id}_chunk{chunk_number}.csv\"\n",
        "            with open(chunk_file_path, \"wb\") as chunk_file:\n",
        "                chunk_file.write(chunk_data)\n",
        "\n",
        "            # Perform backtest on the current chunk\n",
        "            result = client.backtest(\n",
        "                file_path=chunk_file_path,\n",
        "                leverage=1,\n",
        "                jupyter_id=\"test\",\n",
        "                file_id=file_id,\n",
        "                chunk_number=chunk_number,\n",
        "                total_chunks=total_chunks,\n",
        "            )\n",
        "\n",
        "            # Process the results of the backtest\n",
        "            for value in result:\n",
        "                print(value)\n",
        "\n",
        "            # Remove the temporary chunk file\n",
        "            os.remove(chunk_file_path)\n",
        "\n",
        "            # Move to the next chunk\n",
        "            chunk_number += 1\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "4Juy2DEZ45kV"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#change to perform_backtest_large_csv(csv_file_path) for large files\n",
        "backtest_result = perform_backtest(csv_file_path)\n",
        "print(backtest_result)\n",
        "for value in backtest_result:\n",
        "    print(value)"
      ],
      "metadata": {
        "id": "zztBlRjJ607M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3bcc247-6c64-41a2-e120-bc2e7cc433ce"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<generator object Client._handle_response_stream at 0x7c66a96597e0>\n",
            "data: {\n",
            "  \"jupyter_id\": \"test\",\n",
            "  \"result_type\": \"Main\",\n",
            "  \"message\": \"Backtest completed\",\n",
            "  \"result\": {\n",
            "    \"static_statistics\": {\n",
            "      \"From\": \"2019-09-08 00:00:00\",\n",
            "      \"Total Trades\": 13,\n",
            "      \"Leverage Applied\": 1.0,\n",
            "      \"Winning Trades\": 8,\n",
            "      \"Losing Trades\": 5,\n",
            "      \"No. of Long Trades\": 13,\n",
            "      \"No. of Short Trades\": 0,\n",
            "      \"Benchmark Return(%)\": 325.632937,\n",
            "      \"Benchmark Return(on $1000)\": 3256.329373,\n",
            "      \"Win Rate\": 61.538462,\n",
            "      \"Winning Streak\": 5,\n",
            "      \"Losing Streak\": 2,\n",
            "      \"Gross Profit\": 4916.886699,\n",
            "      \"Net Profit\": 4897.386699,\n",
            "      \"Average Profit\": 376.722054,\n",
            "      \"Maximum Drawdown(%)\": 6.389422,\n",
            "      \"Average Drawdown(%)\": 1.586462,\n",
            "      \"Largest Win\": 3764.999505,\n",
            "      \"Average Win\": 651.659651,\n",
            "      \"Largest Loss\": -98.561911,\n",
            "      \"Average Loss\": -63.178102,\n",
            "      \"Maximum Holding Time\": \"156 days 0:0:0\",\n",
            "      \"Average Holding Time\": \"50 days 18:27:41\",\n",
            "      \"Maximum Adverse Excursion\": 11.127804,\n",
            "      \"Average Adverse Excursion\": 4.297222,\n",
            "      \"Sharpe Ratio\": 7.22914,\n",
            "      \"Sortino Ratio\": 174.022254,\n",
            "      \"To\": \"2024-01-01 00:00:00\"\n",
            "    },\n",
            "    \"compound_statistics\": {\n",
            "      \"flag\": \"Trades Executed: 13\",\n",
            "      \"Initial Balance\": 1000.0,\n",
            "      \"Leverage Applied\": 1.0,\n",
            "      \"Number of Trades\": 13,\n",
            "      \"Profit Percentage\": 1051.374797,\n",
            "      \"Maximum Drawdown\": 17.450515,\n",
            "      \"Average Drawdown\": 4.197286,\n",
            "      \"Time to Recovery(TTR)\": \"397.000000 days\",\n",
            "      \"Average TTR\": \"254.666667 days\",\n",
            "      \"Maximum PNL\": 3899.418012,\n",
            "      \"Minimum PNL\": -779.721268,\n",
            "      \"Max Portfolio Balance\": 11513.747973,\n",
            "      \"Minimumm Portfolio Balance\": 936.105779,\n",
            "      \"Final Balance\": 11513.747973,\n",
            "      \"Total Fee\": 94.40317\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7BPpNAHS7ISN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}